import pandas as pd
import numpy as np
import streamlit as st
import networkx as nx
import folium
from streamlit_folium import st_folium
import ast
from Hamilton import HamiltonProgramming
from Euler import EulerProgramming
import sys
import os
from time import sleep
from tqdm import tqdm
import re
import json
import concurrent.futures
from openai import OpenAI

# å¢åŠ é€’å½’æ·±åº¦é™åˆ¶ï¼ˆä¸´æ—¶æ–¹æ¡ˆï¼‰
sys.setrecursionlimit(2000)

# OpenAI API é…ç½®
base_url = "http://123.129.219.111:3000/v1"
api_key = "sk-J4OU0nswdAQEmN7y7pS9ytPedSvEC8NXCOhuBX5GIz3dXz3c"
max_try_num = 5
max_thread_num = 8
parse_json = True
gpt_model = "gpt-4o"
max_tokens = 4096
temperature = 0.5

# æ™¯ç‚¹åˆ—è¡¨
spot_list = ['ä¸‰ä¸€å…«çƒˆå£«çºªå¿µç¢‘', 'ä¸´æ¹–è½©', 'ä¹¾éš†åŠæœˆå°è¯—ç¢‘', 'ä¹¾éš†è¯—ç¢‘', 'åè¡¨', 'åšé›…å¡”', 'å«ç”Ÿé—´', 'å›¾ä¹¦é¦†', 'åŸƒå¾·åŠ Â·æ–¯è¯ºä¹‹å¢“', 
             'å¡ä¸‡ææ–¯åƒ', 'å¡å…‹å‹’åšç‰©é¦†', 'å¤§æ°´æ³•çŸ³æ„ä»¶', 'æ…ˆæµå¯ºå±±é—¨', 'æ–‡åˆ›', 'æ–­æ¡¥æ®‹é›ªçŸ³åŠæ¥£', 'æ–°å¤ªé˜³', 'æ—¥æ™·', 'æœ—æ¶¦å›­', 
             'æœªåæ¹–å£', 'æœªåæ¹–çŸ³', 'æå¤§é’Šåƒ', 'æŸ³æµªé—»èºçŸ³åŠæ¥£', 'æ ¡å²é¦†', 'æ ¡æ™¯äº­', 'æ¤æ ‘ç¢‘', 'ç‡•å—å›­å£', 'ç™¾å‘¨å¹´çºªå¿µè®²å ‚', 
             'çŸ³èˆ«', 'çŸ³é›•å±é£', 'çº¢æ¹–å£', 'ç¿»å°¾çŸ³é±¼', 'èŠ±ç¥åº™', 'èŒœå›­æ¢…çŸ³ç¢‘', 'è·èŠ±æ± å£', 'è‘›åˆ©æ™®æ•™æˆä¹‹å¢“', 'è”¡å…ƒåŸ¹åƒ', 
             'è¥¿å—è”å¤§çºªå¿µç¢‘', 'è¥¿é—¨', 'èµ–æœ´å¾å’Œå¤ä»å¾·å¢“', 'é’Ÿäº­', 'é•œæ˜¥å›­', 'é™å›­', 'é²æ–¯äº­']

# æ¨èæ¨¡æ¿
template = """
ä½ æ˜¯ä¸€ååŒ—äº¬å¤§å­¦çš„å¯¼æ¸¸ï¼ŒåŒ—äº¬å¤§å­¦æ ¡å†…åŒ…å«ä»¥ä¸‹æ™¯ç‚¹ã€‚\n\n{spot_list}
è¯·æ ¹æ®ä»¥ä¸‹æ¸¸å®¢éœ€æ±‚ç»™å‡ºæ¨èçš„5-10ä¸ªæ™¯ç‚¹åºåˆ—ï¼Œè¿”å›ä¸€ä¸ªjsonåˆ—è¡¨ï¼Œä¸è¦è¿”å›å…¶ä»–å†…å®¹ã€‚
æ¸¸å®¢æè¿°:\n\n{text}
"""

# JSON è§£æç±»
class ParseJson:
    def __init__(self):
        super().__init__()

    def replace_newlines(self, match):
        return match.group(0).replace('\n', '\\n').replace('\r', '\\r')

    def clean_json_str(self, json_str: str) -> str:
        json_str = json_str.replace("None", "null")
        match = re.search(r'```json(.*?)```', json_str, re.DOTALL)
        if match:
            json_str = match.group(1)
        match = re.search(r'```(.*?)```', json_str, re.DOTALL)
        if match:
            json_str = match.group(1)
        json_str = re.sub(r'("(?:\\.|[^"\\])*")', self.replace_newlines, json_str)
        json_str = re.sub(r',\s*}', '}', json_str)
        json_str = re.sub(r',\s*]', ']', json_str)
        json_str = re.sub(r'\"\s+\"', '\",\"', json_str)
        json_str = json_str.replace("True", "true").replace("False", "false")
        return json_str

    def txt2obj(self, text):
        try:
            text = self.clean_json_str(text)
            return json.loads(text)
        except Exception as e:
            print(e)
            return None

# ChatCompletion ç±»
class ChatCompletion:
    def __init__(self, chunks):
        self.chunks = chunks
        self.template = template
        if parse_json:
            self.parse_json = ParseJson()

    def _get_chat_completion(self, chunk):
        messages = [{"role": "user", "content": template.format(spot_list=spot_list, text=chunk)}]
        client = OpenAI(api_key=api_key, base_url=base_url)
        chat_completion = client.chat.completions.create(
            model=gpt_model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
            frequency_penalty=0,
            presence_penalty=0
        )
        if parse_json:
            return self.parse_json.txt2obj(chat_completion.choices[0].message.content)
        return chat_completion.choices[0].message.content

    def get_chat_completion(self, chunk):
        retry = 0
        while retry < max_try_num:
            try:
                return self._get_chat_completion(chunk)
            except Exception as e:
                retry += 1
                sleep(0.1 * retry)
                print(e)
        else:
            raise Exception("Max try number reached.")
            return None

    def complete(self):
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_thread_num) as executor:
            future_results = list(tqdm(executor.map(self.get_chat_completion, self.chunks), total=len(self.chunks)))
        return future_results

# æ•°æ®åŠ è½½ï¼ˆç¼“å­˜ä¼˜åŒ–ï¼‰
@st.cache_data
def load_data():
    df = pd.read_csv("./data/pku_all_simple_paths_15.csv")
    locations_df = pd.read_csv("./data/pku_locations_updated.csv")
    node_coordinates_df = pd.read_csv("./data/pku_walk_node_locations.csv")
    
    # è·¯å¾„è¿‡æ»¤
    df = df[(df['é¢„è®¡æ­¥è¡Œæ—¶é—´_åˆ†é’Ÿ'] <= 8.4) & (df['é¢„è®¡æ­¥è¡Œæ—¶é—´_åˆ†é’Ÿ'] >= 6.6)]
    Simple_df = df.copy()
    Simple_df["æ— å‘è¾¹"] = Simple_df.apply(lambda row: tuple(sorted([row["èµ·ç‚¹"], row["ç»ˆç‚¹"]])), axis=1)
    Simple_df_cleaned = Simple_df.loc[Simple_df.groupby("æ— å‘è¾¹")["é¢„è®¡æ­¥è¡Œæ—¶é—´_åˆ†é’Ÿ"].idxmin()].reset_index(drop=True)
    simple_df = Simple_df_cleaned.drop(columns=["æ— å‘è¾¹"])
    
    # åœ°ç‚¹æ•°æ®å¤„ç†
    locations_df["ç»åº¦"] = locations_df["ç»çº¬åº¦"].apply(lambda x: float(x.split(",")[0]))
    locations_df["çº¬åº¦"] = locations_df["ç»çº¬åº¦"].apply(lambda x: float(x.split(",")[1]))
    locations_df[["lng", "lat"]] = locations_df["ç»çº¬åº¦"].str.split(",", expand=True).astype(float)
    restricted = {"æ¡¥", "æ¤…", "å«ç”Ÿé—´", "æ–‡åˆ›"}
    condition = (~locations_df["åç§°"].str.extract(f"({'|'.join(restricted)})")[0].notna()) | (locations_df["æ˜¯å¦åœ¨æ ¡å†…"] == "æ ¡å†…")
    locations_df = locations_df[condition].copy()
    
    return df, simple_df, locations_df, node_coordinates_df

# åŠ è½½æ•°æ®
df, simple_df, locations_df, node_coordinates_df = load_data()

# æ ¡å›­è¾¹ç•Œåæ ‡
boundary_coords = [
    (39.9851791, 116.3004617), (39.9864006, 116.3003677), (39.9863900, 116.2994966),
    (39.9931543, 116.2984634), (39.9931592, 116.2985974), (39.9933919, 116.2985916),
    (39.9933893, 116.2984734), (39.9939562, 116.2984578), (39.9948007, 116.2984264),
    (39.9958545, 116.2983911), (39.9961909, 116.3008489), (39.9962501, 116.3011623),
    (39.9963362, 116.3013332), (39.9965626, 116.3015876), (39.9968540, 116.3018948),
    (39.9973739, 116.3024428), (39.9975695, 116.3028049), (39.9977573, 116.3032563),
    (39.9978738, 116.3038116), (39.9982026, 116.3053797), (39.9982346, 116.3056759),
    (39.9982373, 116.3058293), (39.9982402, 116.3059979), (39.9970351, 116.3062102),
    (39.9970828, 116.3067154), (39.9957638, 116.3069369), (39.9959020, 116.3089361),
    (39.9929106, 116.3091399), (39.9907323, 116.3093135), (39.9906958, 116.3092952),
    (39.9888646, 116.3094595), (39.9887974, 116.3094367), (39.9887223, 116.3094698),
    (39.9879948, 116.3095240), (39.9879245, 116.3095036), (39.9878347, 116.3095240),
    (39.9868598, 116.3095834), (39.9867679, 116.3095553), (39.9866939, 116.3095894),
    (39.9864591, 116.3095878), (39.9860867, 116.3095845), (39.9857161, 116.3093521),
    (39.9853308, 116.3093613), (39.9853151, 116.3085630), (39.9852700, 116.3054565),
    (39.9851791, 116.3004617)
]

# Streamlit é¡µé¢å¸ƒå±€
st.title("åŒ—äº¬å¤§å­¦æ¸¸è§ˆè·¯å¾„è§„åˆ’å™¨")
st.markdown("è¯·è¾“å…¥æ‚¨çš„æ¸¸è§ˆéœ€æ±‚ï¼ˆå¦‚â€˜æˆ‘å–œæ¬¢å»åœ¨æ ¡å­¦ç”Ÿå¤šçš„åœ°æ–¹â€™ï¼‰ï¼Œç³»ç»Ÿå°†æ¨èæ™¯ç‚¹å¹¶è§„åˆ’æœ€çŸ­è·¯å¾„ã€‚")

# ç¼“å­˜åœ°å›¾åˆå§‹åŒ–ï¼ˆæ¢å¤ OpenStreetMap ç“¦ç‰‡ï¼‰
@st.cache_resource
def init_map(center):
    m = folium.Map(location=center, zoom_start=16, tiles="OpenStreetMap", control_scale=True)
    return m

# åˆå§‹åŒ–åœ°å›¾ï¼ˆä»…è¾¹ç•Œï¼‰
center = [locations_df["lat"].mean(), locations_df["lng"].mean()]
m = init_map(center)
folium.PolyLine(boundary_coords, color="black", weight=2.5, opacity=0.8).add_to(m)

# ç¼“å­˜APIè°ƒç”¨ç»“æœ
@st.cache_data
def get_recommended_spots(user_input):
    chatbot = ChatCompletion([user_input])
    results = chatbot.complete()
    return [x for x in results[0] if x in spot_list and x in locations_df["åç§°"].tolist()][:8]  # é™åˆ¶æœ€å¤š8ä¸ªæ™¯ç‚¹

# ç”¨æˆ·è¾“å…¥å’ŒæŒ‰é’®
user_input = st.text_area("è¯·è¾“å…¥æ‚¨çš„æ¸¸è§ˆéœ€æ±‚ï¼š", value="æˆ‘å–œæ¬¢å»åœ¨æ ¡å­¦ç”Ÿå¤šçš„åœ°æ–¹")
if st.button("è·å–æ¨èæ™¯ç‚¹å¹¶è§„åˆ’è·¯å¾„"):
    # è°ƒç”¨å¤§æ¨¡å‹è·å–æ¨èæ™¯ç‚¹
    with st.spinner("æ­£åœ¨è·å–æ¨èæ™¯ç‚¹..."):
        recommended_spots = get_recommended_spots(user_input)
        if not recommended_spots:
            st.error("âŒ æ— æ³•è·å–æœ‰æ•ˆæ¨èæ™¯ç‚¹ï¼Œè¯·æ£€æŸ¥è¾“å…¥æˆ– API é…ç½®ã€‚")
        else:
            st.success(f"âœ… æ¨èçš„æ™¯ç‚¹åºåˆ—ï¼š{recommended_spots}")

    # ä½¿ç”¨FeatureGroupåˆ†å±‚ç®¡ç†æ ‡è®°ï¼ˆæ¢å¤é»˜è®¤ç»¿è‰²æ ‡è®°ï¼‰
    marker_group = folium.FeatureGroup(name="Attractions").add_to(m)
    marker_dict = {}
    for _, row in locations_df[locations_df["åç§°"].isin(recommended_spots)].iterrows():
        folium.Marker(
            location=[row["çº¬åº¦"], row["ç»åº¦"]],
            tooltip=row["åç§°"],
            popup=row["åç§°"],
            # ç§»é™¤è‡ªå®šä¹‰å›¾æ ‡ï¼Œä½¿ç”¨é»˜è®¤ç»¿è‰²æ ‡è®°
        ).add_to(marker_group)
        marker_dict[row["åç§°"]] = (row["çº¬åº¦"], row["ç»åº¦"])

    # è·¯å¾„è§„åˆ’
    selected_nodes = recommended_spots
    if len(selected_nodes) < 2:
        st.warning("è¯·ç¡®ä¿æ¨èçš„æ™¯ç‚¹æ•°é‡è‡³å°‘ä¸º2ä¸ª")
    else:
        # è·¯å¾„è¿‡æ»¤ï¼ˆè¿›ä¸€æ­¥é™åˆ¶è¾¹æ•°ï¼‰
        Filtered_df = df[df["èµ·ç‚¹"].isin(selected_nodes) & df["ç»ˆç‚¹"].isin(selected_nodes)]
        filtered_df = Filtered_df[['èµ·ç‚¹', 'ç»ˆç‚¹', 'é¢„è®¡æ­¥è¡Œæ—¶é—´_åˆ†é’Ÿ']]
        simple_Filtered_df = simple_df[simple_df["èµ·ç‚¹"].isin(selected_nodes) & simple_df["ç»ˆç‚¹"].isin(selected_nodes)]
        simple_filtered_df = simple_Filtered_df[['èµ·ç‚¹', 'ç»ˆç‚¹', 'é¢„è®¡æ­¥è¡Œæ—¶é—´_åˆ†é’Ÿ']]
        
        # é™åˆ¶å­å›¾è§„æ¨¡ï¼ˆæœ€å¤šä¿ç•™ 50 æ¡è¾¹ï¼‰
        if len(filtered_df) > 50:
            filtered_df = filtered_df.nsmallest(50, 'é¢„è®¡æ­¥è¡Œæ—¶é—´_åˆ†é’Ÿ')
        if len(simple_filtered_df) > 50:
            simple_filtered_df = simple_filtered_df.nsmallest(50, 'é¢„è®¡æ­¥è¡Œæ—¶é—´_åˆ†é’Ÿ')
        
        # åˆ›å»ºè¾¹åˆ—è¡¨
        edges = list(filtered_df.itertuples(index=False, name=None))
        edge_pairs = [(u, v) for u, v, _ in edges]
        simple_edges = list(simple_filtered_df.itertuples(index=False, name=None))
        simple_edge_pairs = [(u, v) for u, v, _ in simple_edges]

        # åˆå§‹åŒ–ä¼˜åŒ–ç±»
        ecp = EulerProgramming()
        ecp.addEdges(edge_pairs)
        hmp = HamiltonProgramming()
        hmp.addEdges(simple_edge_pairs)
        best_path = None
        best_time = float("inf")
        best_type = None

        # åˆ¤æ–­å“ˆå¯†é¡¿é€šè·¯
        with st.spinner("Gurobi æ­£åœ¨åˆ¤æ–­å“ˆå¯†é¡¿é€šè·¯..."):
            try:
                hmp.HamiltonPath_solver()
                if hasattr(hmp, "hamiltonian_path"):
                    path = hmp.hamiltonian_path
                    hamilton_time = 0
                    missing_edges = []
                    for u, v in path:
                        sub = simple_filtered_df[((simple_filtered_df["èµ·ç‚¹"] == str(u)) & (simple_filtered_df["ç»ˆç‚¹"] == str(v))) |
                                                 ((simple_filtered_df["èµ·ç‚¹"] == str(v)) & (simple_filtered_df["ç»ˆç‚¹"] == str(u)))]
                        if not sub.empty:
                            hamilton_time += sub["é¢„è®¡æ­¥è¡Œæ—¶é—´_åˆ†é’Ÿ"].min()
                        else:
                            missing_edges.append((u, v))
                    if not missing_edges:
                        st.success("âœ… æ•°å­¦è§„åˆ’åˆ¤æ–­ï¼šå­˜åœ¨å“ˆå¯†é¡¿é€šè·¯")
                        best_path = path
                        best_time = hamilton_time
                        best_type = "å“ˆå¯†é¡¿é€šè·¯"
                    else:
                        st.warning(f"âš ï¸ å“ˆå¯†é¡¿é€šè·¯å­˜åœ¨ï¼Œä½†ä»¥ä¸‹è¾¹æ— é¢„è®¡æ—¶é—´æ•°æ®: {missing_edges}")
                else:
                    st.error("âŒ æ•°å­¦è§„åˆ’åˆ¤æ–­ï¼šä¸å­˜åœ¨å“ˆå¯†é¡¿é€šè·¯")
            except Exception as e:
                st.error(f"âŒ å“ˆå¯†é¡¿è·¯å¾„æ±‚è§£å¤±è´¥: {str(e)}")

        # åˆ¤æ–­æ¬§æ‹‰è·¯å¾„
        with st.spinner("Gurobi æ­£åœ¨åˆ¤æ–­æ¬§æ‹‰è·¯å¾„..."):
            try:
                ecp.EulerPath_solver()
                if hasattr(ecp, "eulerian_path"):
                    path = ecp.eulerian_path
                    euler_time = 0
                    missing_edges = []
                    for u, v in path:
                        sub = filtered_df[((filtered_df["èµ·ç‚¹"] == str(u)) & (filtered_df["ç»ˆç‚¹"] == str(v))) |
                                         ((filtered_df["èµ·ç‚¹"] == str(v)) & (filtered_df["ç»ˆç‚¹"] == str(u)))]
                        if not sub.empty:
                            euler_time += sub["é¢„è®¡æ­¥è¡Œæ—¶é—´_åˆ†é’Ÿ"].min()
                        else:
                            missing_edges.append((u, v))
                    if not missing_edges:
                        st.success("âœ… æ•°å­¦è§„åˆ’åˆ¤æ–­ï¼šå­˜åœ¨æ¬§æ‹‰è·¯å¾„")
                        if euler_time < best_time:
                            best_path = path
                            best_time = euler_time
                            best_type = "æ¬§æ‹‰è·¯å¾„"
                    else:
                        st.warning(f"âš ï¸ æ¬§æ‹‰è·¯å¾„å­˜åœ¨ï¼Œä½†ä»¥ä¸‹è¾¹æ— é¢„è®¡æ—¶é—´æ•°æ®: {missing_edges}")
                else:
                    st.error("âŒ æ•°å­¦è§„åˆ’åˆ¤æ–­ï¼šä¸å­˜åœ¨æ¬§æ‹‰è·¯å¾„")
            except Exception as e:
                st.error(f"âŒ æ¬§æ‹‰è·¯å¾„æ±‚è§£å¤±è´¥: {str(e)}")

        # ä¿å­˜ç»“æœåˆ° session_state
        if best_path is not None:
            st.session_state.best_path = best_path
            st.session_state.best_time = best_time
            st.session_state.best_type = best_type
        else:
            st.error("âŒ æ— å¯è¡Œè·¯å¾„")

        # æ˜¾ç¤ºç»“æœ
        if "best_path" in st.session_state:
            best_path = st.session_state.best_path
            best_time = st.session_state.best_time
            best_type = st.session_state.best_type

            st.markdown(f"ğŸ† **æ›´ä¼˜æ–¹æ¡ˆä¸ºï¼š{best_type}**")
            st.markdown(f"ğŸ”€ è·¯å¾„ï¼š{' -> '.join([str(u) for u, v in best_path] + [str(best_path[-1][1])])}")
            st.markdown(f"ğŸ•’ é¢„è®¡æœ€çŸ­æ­¥è¡Œæ—¶é—´ï¼š{best_time:.1f} åˆ†é’Ÿ")

            # ä¼˜åŒ–è·¯å¾„åæ ‡ç”Ÿæˆï¼šé‡‡æ ·å…³é”®ç‚¹
            df["è·¯å¾„èŠ‚ç‚¹"] = df["è·¯å¾„èŠ‚ç‚¹"].apply(ast.literal_eval)
            
            def get_full_path_coordinates(best_path, path_detail_df, node_id_to_coord, max_points=100):
                full_node_list = []
                for u, v in best_path:
                    match = path_detail_df[
                        ((path_detail_df["èµ·ç‚¹"] == u) & (path_detail_df["ç»ˆç‚¹"] == v)) |
                        ((path_detail_df["èµ·ç‚¹"] == v) & (path_detail_df["ç»ˆç‚¹"] == u))
                    ]
                    if not match.empty:
                        best_row = match.sort_values("é¢„è®¡æ­¥è¡Œæ—¶é—´_åˆ†é’Ÿ").iloc[0]
                        node_ids = best_row["è·¯å¾„èŠ‚ç‚¹"]
                        if node_ids[0] != node_ids[-1] and full_node_list and full_node_list[-1] == node_ids[0]:
                            node_ids = node_ids[1:]  # é¿å…é‡å¤
                        full_node_list.extend(node_ids)
                # é‡‡æ ·è·¯å¾„ç‚¹ï¼Œé™åˆ¶æœ€å¤§ç‚¹æ•°
                if len(full_node_list) > max_points:
                    step = len(full_node_list) // max_points
                    full_node_list = full_node_list[::step][:max_points]
                return [node_id_to_coord[node] for node in full_node_list if node in node_id_to_coord]
            
            # è·å–èŠ‚ç‚¹åæ ‡
            node_id_to_coord = dict(zip(node_coordinates_df["node"], zip(node_coordinates_df["lat"], node_coordinates_df["lng"])))
            
            # ç»˜åˆ¶è·¯å¾„ï¼ˆä½¿ç”¨FeatureGroupï¼Œä¿æŒçº¢è‰²ï¼‰
            path_group = folium.FeatureGroup(name="Path").add_to(m)
            path_coords = get_full_path_coordinates(best_path, df, node_id_to_coord)
            if path_coords:
                folium.PolyLine(
                    path_coords,
                    color="red",
                    weight=5,
                    opacity=0.8,
                    tooltip=f"{best_type}ï¼Œé¢„è®¡ {best_time:.1f} åˆ†é’Ÿ"
                ).add_to(path_group)

    # æ·»åŠ å›¾å±‚æ§åˆ¶
    folium.LayerControl().add_to(m)

# æ˜¾ç¤ºåœ°å›¾ï¼ˆä¼˜åŒ–å°ºå¯¸ï¼‰
st_data = st_folium(m, width=600, height=400, returned_objects=[])
